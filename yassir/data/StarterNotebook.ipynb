{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn import cluster\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn import pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average speed, and use that \n",
    "class AvgSpeed(BaseEstimator, RegressorMixin):\n",
    "    def fit(self, X, y):\n",
    "        if 'Trip_distance' not in X.columns:\n",
    "            raise KeyError('X Dataframe needs to have column \"Trip_distance\"')\n",
    "        self.avg = (y / X['Trip_distance']).mean()\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        if 'Trip_distance' not in X.columns:\n",
    "            raise KeyError('X Dataframe needs to have column \"Trip_distance\"')\n",
    "        return self.avg * X['Trip_distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Yassir/Train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-35020484fc04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/Yassir/Train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/Yassir/Train.csv'"
     ]
    }
   ],
   "source": [
    "# load training\n",
    "training = pd.read_csv('../data/Yassir/Train.csv').set_index('ID')\n",
    "training['Timestamp'] = pd.to_datetime(training['Timestamp'])\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ETA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000V4BQX</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003WBC5J</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004O4X3A</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006CEI5B</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009G0M2T</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ETA\n",
       "ID           \n",
       "000V4BQX    0\n",
       "003WBC5J    0\n",
       "004O4X3A    0\n",
       "006CEI5B    0\n",
       "009G0M2T    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample set \n",
    "sample_set = pd.read_csv('../data/Yassir/SampleSubmission (13).csv').set_index('ID')\n",
    "sample_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Origin_lat</th>\n",
       "      <th>Origin_lon</th>\n",
       "      <th>Destination_lat</th>\n",
       "      <th>Destination_lon</th>\n",
       "      <th>Trip_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000V4BQX</th>\n",
       "      <td>2019-12-21 05:52:37+00:00</td>\n",
       "      <td>2.981</td>\n",
       "      <td>36.688</td>\n",
       "      <td>2.978</td>\n",
       "      <td>36.754</td>\n",
       "      <td>17549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003WBC5J</th>\n",
       "      <td>2019-12-25 21:38:53+00:00</td>\n",
       "      <td>3.032</td>\n",
       "      <td>36.769</td>\n",
       "      <td>3.074</td>\n",
       "      <td>36.751</td>\n",
       "      <td>7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004O4X3A</th>\n",
       "      <td>2019-12-29 21:30:29+00:00</td>\n",
       "      <td>3.035</td>\n",
       "      <td>36.711</td>\n",
       "      <td>3.010</td>\n",
       "      <td>36.758</td>\n",
       "      <td>10194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006CEI5B</th>\n",
       "      <td>2019-12-31 22:51:57+00:00</td>\n",
       "      <td>2.902</td>\n",
       "      <td>36.738</td>\n",
       "      <td>3.208</td>\n",
       "      <td>36.698</td>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009G0M2T</th>\n",
       "      <td>2019-12-28 21:47:22+00:00</td>\n",
       "      <td>2.860</td>\n",
       "      <td>36.692</td>\n",
       "      <td>2.828</td>\n",
       "      <td>36.696</td>\n",
       "      <td>4513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Timestamp  Origin_lat  Origin_lon  Destination_lat  \\\n",
       "ID                                                                            \n",
       "000V4BQX 2019-12-21 05:52:37+00:00       2.981      36.688            2.978   \n",
       "003WBC5J 2019-12-25 21:38:53+00:00       3.032      36.769            3.074   \n",
       "004O4X3A 2019-12-29 21:30:29+00:00       3.035      36.711            3.010   \n",
       "006CEI5B 2019-12-31 22:51:57+00:00       2.902      36.738            3.208   \n",
       "009G0M2T 2019-12-28 21:47:22+00:00       2.860      36.692            2.828   \n",
       "\n",
       "          Destination_lon  Trip_distance  \n",
       "ID                                        \n",
       "000V4BQX           36.754          17549  \n",
       "003WBC5J           36.751           7532  \n",
       "004O4X3A           36.758          10194  \n",
       "006CEI5B           36.698          32768  \n",
       "009G0M2T           36.696           4513  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing data\n",
    "testing = pd.read_csv('../data/Yassir/Test (8).csv').set_index('ID')\n",
    "testing['Timestamp'] = pd.to_datetime(testing['Timestamp'])\n",
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dewpoint_2m_temperature</th>\n",
       "      <th>maximum_2m_air_temperature</th>\n",
       "      <th>mean_2m_air_temperature</th>\n",
       "      <th>mean_sea_level_pressure</th>\n",
       "      <th>minimum_2m_air_temperature</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>u_component_of_wind_10m</th>\n",
       "      <th>v_component_of_wind_10m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>290.630524</td>\n",
       "      <td>296.434662</td>\n",
       "      <td>294.125061</td>\n",
       "      <td>101853.617188</td>\n",
       "      <td>292.503998</td>\n",
       "      <td>100806.351562</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>3.561323</td>\n",
       "      <td>0.941695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>289.135284</td>\n",
       "      <td>298.432404</td>\n",
       "      <td>295.551666</td>\n",
       "      <td>101225.164062</td>\n",
       "      <td>293.337921</td>\n",
       "      <td>100187.250000</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>5.318593</td>\n",
       "      <td>3.258237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>287.667694</td>\n",
       "      <td>296.612122</td>\n",
       "      <td>295.182831</td>\n",
       "      <td>100806.617188</td>\n",
       "      <td>293.674316</td>\n",
       "      <td>99771.414062</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>8.447649</td>\n",
       "      <td>3.172982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>287.634644</td>\n",
       "      <td>297.173737</td>\n",
       "      <td>294.368134</td>\n",
       "      <td>101240.929688</td>\n",
       "      <td>292.376221</td>\n",
       "      <td>100200.843750</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>5.991428</td>\n",
       "      <td>2.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>286.413788</td>\n",
       "      <td>294.284851</td>\n",
       "      <td>292.496979</td>\n",
       "      <td>101131.750000</td>\n",
       "      <td>289.143066</td>\n",
       "      <td>100088.500000</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>6.962730</td>\n",
       "      <td>2.655364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  dewpoint_2m_temperature  maximum_2m_air_temperature  \\\n",
       "0  2019-11-01               290.630524                  296.434662   \n",
       "1  2019-11-02               289.135284                  298.432404   \n",
       "2  2019-11-03               287.667694                  296.612122   \n",
       "3  2019-11-04               287.634644                  297.173737   \n",
       "4  2019-11-05               286.413788                  294.284851   \n",
       "\n",
       "   mean_2m_air_temperature  mean_sea_level_pressure  \\\n",
       "0               294.125061            101853.617188   \n",
       "1               295.551666            101225.164062   \n",
       "2               295.182831            100806.617188   \n",
       "3               294.368134            101240.929688   \n",
       "4               292.496979            101131.750000   \n",
       "\n",
       "   minimum_2m_air_temperature  surface_pressure  total_precipitation  \\\n",
       "0                  292.503998     100806.351562             0.004297   \n",
       "1                  293.337921     100187.250000             0.001767   \n",
       "2                  293.674316      99771.414062             0.000797   \n",
       "3                  292.376221     100200.843750             0.000393   \n",
       "4                  289.143066     100088.500000             0.004658   \n",
       "\n",
       "   u_component_of_wind_10m  v_component_of_wind_10m  \n",
       "0                 3.561323                 0.941695  \n",
       "1                 5.318593                 3.258237  \n",
       "2                 8.447649                 3.172982  \n",
       "3                 5.991428                 2.236700  \n",
       "4                 6.962730                 2.655364  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weather data\n",
    "weather_df = pd.read_csv('../data/Yassir/Weather.csv')\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make train and OOT set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 7), (63924, 7))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure sorted by date\n",
    "training = training.sort_values('Timestamp')\n",
    "train_df = training.iloc[:-20000]\n",
    "oot_df = training.iloc[-20000:]\n",
    "oot_df.shape,train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVG Speed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([0.00819898, 0.00813413, 0.01284361, 0.01280761, 0.01328516]),\n",
       "  'score_time': array([0.00377679, 0.00445986, 0.00536752, 0.00395322, 0.00427747]),\n",
       "  'test_score': array([-608.83239483, -619.45547343, -642.25524582, -602.10699022,\n",
       "         -628.52682296])},\n",
       " 620.2353854497962,\n",
       " 14.233041543856139)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline model\n",
    "split = model_selection.TimeSeriesSplit(n_splits=5)\n",
    "result= model_selection.cross_validate(AvgSpeed(),train_df, train_df['ETA'],cv=split,\n",
    "                               scoring='neg_root_mean_squared_error')\n",
    "result, -np.mean(result['test_score']), np.std(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632.4052293330434"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check score on Dev set\n",
    "reg = AvgSpeed()\n",
    "reg.fit(train_df, train_df.ETA)\n",
    "np.sqrt(metrics.mean_squared_error(oot_df.ETA, reg.predict(oot_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10475614041193526"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model on all data\n",
    "reg = AvgSpeed()\n",
    "reg.fit(training, training.ETA)\n",
    "reg.avg # time / distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Origin_lat</th>\n",
       "      <th>Origin_lon</th>\n",
       "      <th>Destination_lat</th>\n",
       "      <th>Destination_lon</th>\n",
       "      <th>Trip_distance</th>\n",
       "      <th>ETA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000V4BQX</th>\n",
       "      <td>2019-12-21 05:52:37+00:00</td>\n",
       "      <td>2.981</td>\n",
       "      <td>36.688</td>\n",
       "      <td>2.978</td>\n",
       "      <td>36.754</td>\n",
       "      <td>17549</td>\n",
       "      <td>1838.365508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003WBC5J</th>\n",
       "      <td>2019-12-25 21:38:53+00:00</td>\n",
       "      <td>3.032</td>\n",
       "      <td>36.769</td>\n",
       "      <td>3.074</td>\n",
       "      <td>36.751</td>\n",
       "      <td>7532</td>\n",
       "      <td>789.023250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004O4X3A</th>\n",
       "      <td>2019-12-29 21:30:29+00:00</td>\n",
       "      <td>3.035</td>\n",
       "      <td>36.711</td>\n",
       "      <td>3.010</td>\n",
       "      <td>36.758</td>\n",
       "      <td>10194</td>\n",
       "      <td>1067.884095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006CEI5B</th>\n",
       "      <td>2019-12-31 22:51:57+00:00</td>\n",
       "      <td>2.902</td>\n",
       "      <td>36.738</td>\n",
       "      <td>3.208</td>\n",
       "      <td>36.698</td>\n",
       "      <td>32768</td>\n",
       "      <td>3432.649209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009G0M2T</th>\n",
       "      <td>2019-12-28 21:47:22+00:00</td>\n",
       "      <td>2.860</td>\n",
       "      <td>36.692</td>\n",
       "      <td>2.828</td>\n",
       "      <td>36.696</td>\n",
       "      <td>4513</td>\n",
       "      <td>472.764462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Timestamp  Origin_lat  Origin_lon  Destination_lat  \\\n",
       "ID                                                                            \n",
       "000V4BQX 2019-12-21 05:52:37+00:00       2.981      36.688            2.978   \n",
       "003WBC5J 2019-12-25 21:38:53+00:00       3.032      36.769            3.074   \n",
       "004O4X3A 2019-12-29 21:30:29+00:00       3.035      36.711            3.010   \n",
       "006CEI5B 2019-12-31 22:51:57+00:00       2.902      36.738            3.208   \n",
       "009G0M2T 2019-12-28 21:47:22+00:00       2.860      36.692            2.828   \n",
       "\n",
       "          Destination_lon  Trip_distance          ETA  \n",
       "ID                                                     \n",
       "000V4BQX           36.754          17549  1838.365508  \n",
       "003WBC5J           36.751           7532   789.023250  \n",
       "004O4X3A           36.758          10194  1067.884095  \n",
       "006CEI5B           36.698          32768  3432.649209  \n",
       "009G0M2T           36.696           4513   472.764462  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run test data through\n",
    "submission = testing.copy()\n",
    "submission['ETA'] = reg.predict(testing)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "submission[['ETA']].to_csv('baseline_submit_base.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do clustering on coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('Coordninates', cluster.KMeans(n_clusters=8),['Origin_lat','Origin_lon',\n",
    "                                                           'Destination_lat','Destination_lon']),\n",
    "            ('Distance', StandardScaler(), ['Trip_distance'])])\n",
    "\n",
    "    # create model\n",
    "pipeline = pipeline.Pipeline(steps=[\n",
    "                          ('preprocessor', preprocessor),\n",
    "    \n",
    "                          ('Regression', LinearRegression())])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fit_time': array([1.34323955, 2.01963997, 2.55939531, 2.17441821, 2.34761739]),\n",
       "  'score_time': array([0.02682281, 0.01882362, 0.01965141, 0.02390814, 0.01146746]),\n",
       "  'test_score': array([-249.51832446, -245.01835477, -259.09680388, -238.69900333,\n",
       "         -238.35198949])},\n",
       " 246.13689518869091,\n",
       " 7.701576746909879)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = model_selection.TimeSeriesSplit(n_splits=5)\n",
    "result= model_selection.cross_validate(pipeline,train_df.drop(columns=['ETA']), train_df['ETA'],cv=split,\n",
    "                               scoring='neg_root_mean_squared_error')\n",
    "result, -np.mean(result['test_score']), np.std(result['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/compose/_column_transformer.py:437: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  warnings.warn(\"Given feature/column names or counts do not match \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "229.61930200628578"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on DEV set\n",
    "pipeline.fit(training.drop(columns=['ETA']), training.ETA)\n",
    "np.sqrt(metrics.mean_squared_error(oot_df.ETA, pipeline.predict(oot_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Origin_lat</th>\n",
       "      <th>Origin_lon</th>\n",
       "      <th>Destination_lat</th>\n",
       "      <th>Destination_lon</th>\n",
       "      <th>Trip_distance</th>\n",
       "      <th>ETA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000V4BQX</th>\n",
       "      <td>2019-12-21 05:52:37+00:00</td>\n",
       "      <td>2.981</td>\n",
       "      <td>36.688</td>\n",
       "      <td>2.978</td>\n",
       "      <td>36.754</td>\n",
       "      <td>17549</td>\n",
       "      <td>1445.301920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003WBC5J</th>\n",
       "      <td>2019-12-25 21:38:53+00:00</td>\n",
       "      <td>3.032</td>\n",
       "      <td>36.769</td>\n",
       "      <td>3.074</td>\n",
       "      <td>36.751</td>\n",
       "      <td>7532</td>\n",
       "      <td>797.927972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004O4X3A</th>\n",
       "      <td>2019-12-29 21:30:29+00:00</td>\n",
       "      <td>3.035</td>\n",
       "      <td>36.711</td>\n",
       "      <td>3.010</td>\n",
       "      <td>36.758</td>\n",
       "      <td>10194</td>\n",
       "      <td>999.720052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006CEI5B</th>\n",
       "      <td>2019-12-31 22:51:57+00:00</td>\n",
       "      <td>2.902</td>\n",
       "      <td>36.738</td>\n",
       "      <td>3.208</td>\n",
       "      <td>36.698</td>\n",
       "      <td>32768</td>\n",
       "      <td>2088.263673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009G0M2T</th>\n",
       "      <td>2019-12-28 21:47:22+00:00</td>\n",
       "      <td>2.860</td>\n",
       "      <td>36.692</td>\n",
       "      <td>2.828</td>\n",
       "      <td>36.696</td>\n",
       "      <td>4513</td>\n",
       "      <td>431.613886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Timestamp  Origin_lat  Origin_lon  Destination_lat  \\\n",
       "ID                                                                            \n",
       "000V4BQX 2019-12-21 05:52:37+00:00       2.981      36.688            2.978   \n",
       "003WBC5J 2019-12-25 21:38:53+00:00       3.032      36.769            3.074   \n",
       "004O4X3A 2019-12-29 21:30:29+00:00       3.035      36.711            3.010   \n",
       "006CEI5B 2019-12-31 22:51:57+00:00       2.902      36.738            3.208   \n",
       "009G0M2T 2019-12-28 21:47:22+00:00       2.860      36.692            2.828   \n",
       "\n",
       "          Destination_lon  Trip_distance          ETA  \n",
       "ID                                                     \n",
       "000V4BQX           36.754          17549  1445.301920  \n",
       "003WBC5J           36.751           7532   797.927972  \n",
       "004O4X3A           36.758          10194   999.720052  \n",
       "006CEI5B           36.698          32768  2088.263673  \n",
       "009G0M2T           36.696           4513   431.613886  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make submission\n",
    "# run test data through\n",
    "submission = testing.copy()\n",
    "submission['ETA'] = pipeline.predict(testing)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[['ETA']].to_csv('kmeans_submit_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what pipeline is doing\n",
    "# extract feature names from pipeline\n",
    "def get_column_names_from_ColumnTransformer(column_transformer):    \n",
    "    col_name = []\n",
    "    for transformer_in_columns in column_transformer.transformers_:#the last transformer is ColumnTransformer's 'remainder'\n",
    "        raw_col_name = transformer_in_columns[2]\n",
    "        methods = transformer_in_columns[0]\n",
    "        if isinstance(transformer_in_columns[1],Pipeline): \n",
    "            transformer = transformer_in_columns[1].steps[-1][1]\n",
    "        else:\n",
    "            transformer = transformer_in_columns[1]\n",
    "        try:\n",
    "            names = transformer.get_feature_names()\n",
    "        except AttributeError: # if no 'get_feature_names' function, use raw column name\n",
    "            names = raw_col_name\n",
    "        if isinstance(names,np.ndarray): # eg.\n",
    "            col_name += [methods + '__'+ str(i) for i in names.tolist()]\n",
    "        elif isinstance(names,list):\n",
    "            col_name += [methods + '__'+ str(i) for i in names]    \n",
    "        elif isinstance(names,str):\n",
    "            col_name.append(methods + '__'+ names)\n",
    "    return col_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Origin_lat', 'Origin_lon', 'Destination_lat', 'Destination_lon']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = get_column_names_from_ColumnTransformer(pipeline.named_steps['preprocessor'])\n",
    "a = pipeline.named_steps['preprocessor']\n",
    "a.transformers[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 2, ..., 5, 5, 0], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.named_transformers_['Coordninates'].predict(train_df[a.transformers[0][2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add weather data and try other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make submission\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
